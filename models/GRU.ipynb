{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3t8fdC578Sa",
        "outputId": "38ad8ba1-7781-4f17-e666-d2b333b30738"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==2.2.0 in /usr/local/lib/python3.12/dist-packages (2.2.0)\n",
            "Requirement already satisfied: torchtext==0.16.2 in /usr/local/lib/python3.12/dist-packages (0.16.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0) (2.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext==0.16.2) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext==0.16.2) (2.32.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchtext==0.16.2) (2.0.2)\n",
            "Requirement already satisfied: torchdata==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torchtext==0.16.2) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0) (12.6.85)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.12/dist-packages (from torchdata==0.7.1->torchtext==0.16.2) (2.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.2.0) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.16.2) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.16.2) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.16.2) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.2.0) (1.3.0)\n",
            "Requirement already satisfied: portalocker>=2.0.0 in /usr/local/lib/python3.12/dist-packages (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.2.0 torchtext==0.16.2\n",
        "!pip install 'portalocker>=2.0.0'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbiii8aF841F",
        "outputId": "aea95e67-9a85-466e-bca2-6f4086133d24"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
            "    await result\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipython-input-1637793204.py\", line 1, in <cell line: 0>\n",
            "    import torch\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/__init__.py\", line 1471, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchtext.datasets import IMDB\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Axy533Wl8-Dx"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device=torch.device(type='cuda',index=0)\n",
        "else:\n",
        "    device=torch.device(type='cpu',index=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91657WCO9Fyo",
        "outputId": "0cac0873-32b7-4b25-a5fc-c1b45e6eff47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded IMDb dataset (25,000 train + 25,000 test)\n"
          ]
        }
      ],
      "source": [
        "train_iter, test_iter = IMDB()\n",
        "print(\"Loaded IMDb dataset (25,000 train + 25,000 test)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVEv9Ocz9H6M",
        "outputId": "76d22bf1-cb8a-4c32-db85-81edb12e1cb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating tokenizer and building vocabulary...\n",
            "\n",
            "Vocabulary built successfully!\n",
            "Total vocabulary size: 100683 words\n",
            "\n",
            " Sample words from vocabulary:\n",
            "['₤250', '₤100', '“you’ve', '“x”', '“sanatorium”', '“playboy”', '“mr', '“jean', '“it’s', '“him”', '“family”', '“consider', '“b”', '“at', '’', '‘revenge’', '‘lifer’', 'üvegtigris', 'über-spy', 'über-annoying', 'ø', 'ís', 'évery', 'étc', 'émigrés', 'écran', 'åmål', 'äänekoski', 'ääliöt', 'ángela', 'ángel', 'ánd', 'álvaro', 'álex', '¿acting', '½/*****', '½*', 'º', '´cos', '´83', '®', '«there', '«the', '«syvsoverskens', '«modern', '«lexx»', '«i', '«farscape»', '«boy', '«bazar»', '«battlestar', '¨una', '¨town', '¨the', '¨scandal', '¨sabretooth', '¨nuit', '¨invitation', '¨gore', '¨by', '¨abe', '¨a', '§12', '£9', '£8', '£300', '£200', '£18', '£16', '¡§october', '¡§just', '¡§galaxy', '¡§astronauts', '¡viva', '¡the', '¡colombians', '\\x97two', '\\x97he', '\\x97are', '\\x97all', '\\x96sensitive', '\\x96russwill', '\\x96organized', '\\x96like', '\\x96knit', '\\x96even', '\\x96conservative', '\\x96but', '\\x96brilliantly', '\\x96-', '\\x91when', '\\x91very', '\\x91that', '\\x91s', '\\x91round', '\\x91quite', '\\x91psycho', '\\x91order', '\\x91movie', '\\x91moments', '\\x91method', '\\x91lubitsch', '\\x91insignificance', '\\x91illusion', '\\x91friends', '\\x91fifth', '\\x91fear', '\\x91doña', '\\x91curious', '\\x91cupido', '\\x91character', '\\x91cause', '\\x91cartoonish', '\\x91bad', '\\x91b', '\\x91arabella', '\\x91alonzo', '\\x8d', '\\x84richard', '\\x84raves', '\\x84predator`', '\\x84orna', '\\x84big', '\\x84batman`', '\\x8014', '~~~rube', '~virginia', '~nancy', '~finally', '~a~', '~2005', '~$3000/lb', '{working', '{whom', '{trumpet', '{thank', '{strathairn}', '{spoiler}', '{spoiler', '{sound', '{seagal}', '{scientific}', '{read', '{neither', '{millard', '{leon', '{king', '{justifiably', '{john', '{jerry}gary', '{james', '{insert', '{imo}', '{however', '{dwight', '{david', '{cut', '{clark', '{check', '{charlotte', '{beefcake', '{a}', '{army}', '{although', '{aka', '{aamir', '{a', 'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz', 'zzzzzzzzzzzzz', 'zzzzz', 'zyuranger', 'zwrite', 'zwartboek', 'zuzz-zuzz', 'zuwarriors', 'zungia', 'zumhofe', 'zukhov', 'zuf', 'zucker/abrams', 'zsa-zsa', 'zowee', 'zouzou', 'zorro`s', 'zorich', 'zords', 'zoom-outs', 'zoom-out', 'zoological', 'zoo/theme', 'zoo-keeper', 'zonked-out', 'zonfeld', 'zone/zombiefest/ghost', 'zomg', 'zomerhitte', 'zombs', 'zombification--supposedly', 'zombies\\x97natch', 'zombies--and']\n"
          ]
        }
      ],
      "source": [
        "print(\"Creating tokenizer and building vocabulary...\")\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for label, text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "print(f\"\\nVocabulary built successfully!\")\n",
        "print(f\"Total vocabulary size: {len(vocab)} words\\n\")\n",
        "\n",
        "\n",
        "print(\" Sample words from vocabulary:\")\n",
        "print(list(vocab.get_stoi().keys())[:200])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqLGRwhA9U_M",
        "outputId": "7ef61eee-13df-410d-b360-1041b0011953"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Example sample:\n",
            "Label: 1\n",
            "Text: I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ev ...\n",
            "Encoded label: 0\n",
            "Tokenized sample words: ['i', 'rented', 'i', 'am', 'curious-yellow', 'from', 'my', 'video', 'store', 'because']\n"
          ]
        }
      ],
      "source": [
        "def text_pipeline(x):\n",
        "    return vocab(tokenizer(x))\n",
        "\n",
        "def label_pipeline(y):\n",
        "    return 1 if y == 'pos' else 0\n",
        "sample_label, sample_text = next(iter(train_iter))\n",
        "print(\"\\n Example sample:\")\n",
        "print(\"Label:\", sample_label)\n",
        "print(\"Text:\", sample_text[:200], \"...\")\n",
        "print(\"Encoded label:\", label_pipeline(sample_label))\n",
        "print(\"Tokenized sample words:\", tokenizer(sample_text)[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBRH8-ZK-IBF",
        "outputId": "415e29f4-3637-474a-f46a-85e133cbefc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " DataLoader created!  Train batches: 391, Test batches: 391\n"
          ]
        }
      ],
      "source": [
        "def collate_batch(batch):\n",
        "    label_list, text_list, lengths = [], [], []\n",
        "    for label, text in batch:\n",
        "        label_list.append(label_pipeline(label))\n",
        "        processed_text = torch.tensor(text_pipeline(text), dtype=torch.int64)\n",
        "        text_list.append(processed_text)\n",
        "        lengths.append(len(processed_text))\n",
        "\n",
        "    text_list = pad_sequence(text_list, batch_first=True)\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    lengths = torch.tensor(lengths)\n",
        "    return text_list, label_list, lengths\n",
        "\n",
        "train_iter, test_iter = IMDB()\n",
        "\n",
        "train_dataloader = DataLoader(list(train_iter), batch_size=64, shuffle=True,\n",
        "                              collate_fn=collate_batch)\n",
        "test_dataloader = DataLoader(list(test_iter), batch_size=64, shuffle=False,\n",
        "                             collate_fn=collate_batch)\n",
        "print(f\" DataLoader created!  Train batches: {len(train_dataloader)}, Test batches: {len(test_dataloader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqgtIgyD-JZp"
      },
      "outputs": [],
      "source": [
        "class GRUClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim, n_layers, dropout):\n",
        "        super(GRUClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.gru = nn.GRU(embed_dim, hidden_dim, num_layers=n_layers,\n",
        "                          batch_first=True, dropout=dropout, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text, lengths):\n",
        "        embedded = self.embedding(text)\n",
        "        packed_output, hidden = self.gru(embedded)\n",
        "        hidden_cat = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
        "        out = self.fc(self.dropout(hidden_cat))\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c-iTDGI-Ovl",
        "outputId": "1429935b-cf7c-4b6d-8a01-de8577ba500d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model initialized on device: cpu\n",
            "Model Parameters:\n",
            "Embedding=100, Hidden=128, Layers=2, Dropout=0.3\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(vocab)\n",
        "embed_dim = 100\n",
        "hidden_dim = 128\n",
        "output_dim = 2\n",
        "n_layers = 2\n",
        "dropout = 0.3\n",
        "\n",
        "model = GRUClassifier(vocab_size, embed_dim, hidden_dim, output_dim, n_layers, dropout)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "print(f\"Model initialized on device: {device}\")\n",
        "print(f\"Model Parameters:\\nEmbedding={embed_dim}, Hidden={hidden_dim}, Layers={n_layers}, Dropout={dropout}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1KXMDFU-QSA"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, dataloader, criterion, optimizer):\n",
        "    model.train()\n",
        "    total_loss, total_correct = 0, 0\n",
        "\n",
        "    for batch_idx, (text, labels, lengths) in enumerate(dataloader):\n",
        "        text, labels = text.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(text, lengths)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "\n",
        "        if batch_idx + 1 == len(dataloader):\n",
        "            print(f\"  Batch {batch_idx+1}/{len(dataloader)} processed.\")\n",
        "\n",
        "    return total_loss / len(dataloader), total_correct / len(dataloader.dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mVx6CLV-TLR"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss, total_correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for text, labels, lengths in dataloader:\n",
        "            text, labels = text.to(device), labels.to(device)\n",
        "            outputs = model(text, lengths)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "            total_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "    return total_loss / len(dataloader), total_correct / len(dataloader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_NR5yKxJZvM",
        "outputId": "25db5451-1d16-4182-c00b-1466e2121921"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1/10\n",
            "  Batch 391/391 processed.\n",
            "Epoch=1, Train Loss=0.0000, Train Acc=100.00\n",
            "Eval Loss=0.0000, Eval Acc=100.00\n",
            "\n",
            " Epoch 2/10\n",
            "  Batch 391/391 processed.\n",
            "Epoch=2, Train Loss=0.0000, Train Acc=100.00\n",
            "Eval Loss=0.0000, Eval Acc=100.00\n",
            "\n",
            " Epoch 3/10\n",
            "  Batch 391/391 processed.\n",
            "Epoch=3, Train Loss=0.0000, Train Acc=100.00\n",
            "Eval Loss=0.0000, Eval Acc=100.00\n",
            "\n",
            " Epoch 4/10\n",
            "  Batch 391/391 processed.\n",
            "Epoch=4, Train Loss=0.0000, Train Acc=100.00\n",
            "Eval Loss=0.0000, Eval Acc=100.00\n",
            "\n",
            " Epoch 5/10\n",
            "  Batch 391/391 processed.\n",
            "Epoch=5, Train Loss=0.0000, Train Acc=100.00\n",
            "Eval Loss=0.0000, Eval Acc=100.00\n",
            "\n",
            " Epoch 6/10\n",
            "  Batch 391/391 processed.\n",
            "Epoch=6, Train Loss=0.0000, Train Acc=100.00\n",
            "Eval Loss=0.0000, Eval Acc=100.00\n",
            "\n",
            " Epoch 7/10\n",
            "  Batch 391/391 processed.\n",
            "Epoch=7, Train Loss=0.0000, Train Acc=100.00\n",
            "Eval Loss=0.0000, Eval Acc=100.00\n",
            "\n",
            " Epoch 8/10\n",
            "  Batch 391/391 processed.\n",
            "Epoch=8, Train Loss=0.0000, Train Acc=100.00\n",
            "Eval Loss=0.0000, Eval Acc=100.00\n",
            "\n",
            " Epoch 9/10\n",
            "  Batch 391/391 processed.\n",
            "Epoch=9, Train Loss=0.0000, Train Acc=100.00\n",
            "Eval Loss=0.0000, Eval Acc=100.00\n",
            "\n",
            " Epoch 10/10\n",
            "  Batch 391/391 processed.\n",
            "Epoch=10, Train Loss=0.0000, Train Acc=100.00\n",
            "Eval Loss=0.0000, Eval Acc=100.00\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\n Epoch {epoch+1}/{num_epochs}\")\n",
        "    train_loss, train_acc = train_epoch(model, train_dataloader, criterion, optimizer)\n",
        "\n",
        "    eval_loss, eval_acc = evaluate(model, test_dataloader, criterion)\n",
        "\n",
        "    print(f\"Epoch={epoch+1}, Train Loss={train_loss:.4f}, Train Acc={train_acc*100:.2f}\")\n",
        "    print(f\"Eval Loss={eval_loss:.4f}, Eval Acc={eval_acc*100:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc7LaqjkNvev"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}